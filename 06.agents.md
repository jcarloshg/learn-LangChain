# ğŸ¤– Best Practices & Tips for Managing Agents in LangChain

> Tools, Agent Types, ReAct Patterns, and Autonomous Systems Mastery Guide

---

## ğŸ“‘ Table of Contents

### Part 1: Best Practices for Agent Management

1. [Understand Agent Types and Choose the Right One](#1-understand-agent-types-and-choose-the-right-one) - Line 8
2. [Define Tools Properly and Completely](#2-define-tools-properly-and-completely) - Line 94
3. [Implement Safe Tool Execution](#3-implement-safe-tool-execution) - Line 205
4. [Build Custom Tool Sets](#4-build-custom-tool-sets) - Line 361
5. [Implement Agent Memory and State Management](#5-implement-agent-memory-and-state-management) - Line 507
6. [Implement Agent Logging and Debugging](#6-implement-agent-logging-and-debugging) - Line 628
7. [Implement Agent Error Handling and Recovery](#7-implement-agent-error-handling-and-recovery) - Line 752
8. [Implement Agent Planning and Reasoning](#8-implement-agent-planning-and-reasoning) - Line 882
9. [Implement Agent Streaming and Real-Time Feedback](#9-implement-agent-streaming-and-real-time-feedback) - Line 1009
10. [Implement Multi-Agent Systems](#10-implement-multi-agent-systems) - Line 1081

### Part 2: Tips & Tricks for Agents

1. [Implement Agent Self-Critique](#trick-1-implement-agent-self-critique) - Line 1203
2. [Implement Agent Thought Tracking](#trick-2-implement-agent-thought-tracking) - Line 1251
3. [Implement Agent Tool Caching](#trick-3-implement-agent-tool-caching) - Line 1292
4. [Implement Dynamic Tool Selection](#trick-4-implement-dynamic-tool-selection) - Line 1325
5. [Implement Agent Explanation Generation](#trick-5-implement-agent-explanation-generation) - Line 1362
6. [Implement Agent Confidence Scoring](#trick-6-implement-agent-confidence-scoring) - Line 1400
7. [Implement Agent Parallelization](#trick-7-implement-agent-parallelization) - Line 1445
8. [Implement Agent A/B Testing](#trick-8-implement-agent-ab-testing) - Line 1475
9. [Implement Agent Personas](#trick-9-implement-agent-personas) - Line 1538
10. [Implement Agent Chain of Thought Prompting](#trick-10-implement-agent-chain-of-thought-prompting) - Line 1569

### Quick Reference & Checklists

- [Quick Reference: Agent Types Comparison](#-quick-reference-agent-types-comparison) - Line 1597
- [Agent Development Checklist](#-agent-development-checklist) - Line 1612
- [Production Agent Checklist](#-production-agent-checklist) - Line 1630

---

## ğŸ“‹ Part 1: Best Practices for Agent Management

### 1. **Understand Agent Types and Choose the Right One**

**Why:** Different agent types have different capabilities. Wrong choice = poor performance or wrong behavior.

```python
from langchain.agents import create_react_agent, create_tool_calling_agent, AgentExecutor
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

llm = ChatOpenAI(model="gpt-4", temperature=0)

# âœ… 1. ReAct Agent (Reasoning + Action)
# Best for: Complex reasoning, multi-step tasks
# Pros: Good at reasoning, transparent thought process
# Cons: Slower, verbose output
react_agent = create_react_agent(
    llm=llm,
    tools=tools,
    prompt=ChatPromptTemplate.from_messages([
        ("system", "You are helpful assistant"),
        ("user", "{input}")
    ])
)
react_executor = AgentExecutor(agent=react_agent, tools=tools, verbose=True)

# âœ… 2. Tool Calling Agent (Function Calling)
# Best for: Fast tool execution, modern models
# Pros: Fast, efficient, native support
# Cons: Less visible reasoning
tool_agent = create_tool_calling_agent(
    llm=llm,
    tools=tools,
    prompt=ChatPromptTemplate.from_messages([
        ("system", "You are helpful"),
        ("user", "{input}")
    ])
)
tool_executor = AgentExecutor(agent=tool_agent, tools=tools)

# âœ… 3. OpenAI Assistants Agent
# Best for: Complex workflows, file handling
# Pros: Feature-rich, persistent, reliable
# Cons: OpenAI-only, requires setup
from langchain.agents.openai_assistant import OpenAIAssistantRunnable

assistant_agent = OpenAIAssistantRunnable.create_assistant(
    name="My Assistant",
    instructions="Help with tasks",
    model="gpt-4",
    tools=tools
)

# âœ… Agent type comparison
agent_comparison = {
    "react": {
        "reasoning": "Excellent",
        "speed": "Medium",
        "transparency": "High",
        "best_for": "Complex reasoning"
    },
    "tool_calling": {
        "reasoning": "Good",
        "speed": "Fast",
        "transparency": "Medium",
        "best_for": "Fast execution"
    },
    "openai_assistant": {
        "reasoning": "Excellent",
        "speed": "Medium",
        "transparency": "High",
        "best_for": "Complex workflows"
    },
}

def select_agent_type(use_case: str):
    """Select agent type based on requirements"""
    if "reasoning" in use_case or "complex" in use_case:
        return "react"
    elif "fast" in use_case or "simple" in use_case:
        return "tool_calling"
    else:
        return "react"
```

---

### 2. **Define Tools Properly and Completely**

**Why:** Poorly defined tools lead to agent confusion, errors, and wrong tool calls.

```python
from langchain.tools import tool
from langchain_core.tools import BaseTool
from pydantic import BaseModel, Field
from typing import Optional

# âœ… 1. Using @tool decorator (Simple)
@tool
def multiply(a: int, b: int) -> int:
    """Multiply two numbers together.

    Args:
        a: First number
        b: Second number
    """
    return a * b

# âœ… 2. Using BaseTool class (Advanced)
class CalculatorInput(BaseModel):
    a: int = Field(description="First number to divide")
    b: int = Field(description="Second number to divide")

class DivideTool(BaseTool):
    name = "divide"
    description = "Divide two numbers. Useful for division operations."
    args_schema = CalculatorInput

    def _run(self, a: int, b: int) -> str:
        """Execute the division"""
        if b == 0:
            return "Error: Cannot divide by zero"
        return str(a / b)

    async def _arun(self, a: int, b: int) -> str:
        """Async execution"""
        return self._run(a, b)

divide_tool = DivideTool()

# âœ… 3. Complete tool definition checklist
class WellDefinedTool(BaseTool):
    """Template for complete tool definition"""

    # Required fields
    name = "tool_name"
    description = """Clear description of what tool does.

    Use this tool when you need to [specific use case].
    """
    args_schema = BaseModel  # Input schema with Field descriptions

    def _run(self, **kwargs) -> str:
        """Synchronous execution"""
        try:
            # Implementation
            result = self._execute(**kwargs)
            return str(result)
        except Exception as e:
            return f"Error: {str(e)}"

    async def _arun(self, **kwargs) -> str:
        """Asynchronous execution (optional but recommended)"""
        return self._run(**kwargs)

    def _execute(self, **kwargs):
        """Actual implementation logic"""
        pass

# âœ… Tool validation utility
class ToolValidator:
    @staticmethod
    def validate_tool(tool: BaseTool) -> dict:
        """Check tool is properly defined"""

        issues = []

        # Check name
        if not tool.name or len(tool.name) == 0:
            issues.append("Tool missing 'name'")

        # Check description
        if not tool.description or len(tool.description) < 10:
            issues.append("Tool description too short")

        # Check args schema
        if not hasattr(tool, 'args_schema'):
            issues.append("Tool missing 'args_schema'")

        # Try a dummy run
        try:
            # Could test with dummy args
            pass
        except Exception as e:
            issues.append(f"Tool execution issue: {str(e)}")

        return {
            "valid": len(issues) == 0,
            "issues": issues
        }

# Usage
validation = ToolValidator.validate_tool(multiply)
print(f"Valid: {validation['valid']}")
```

---

### 3. **Implement Safe Tool Execution**

**Why:** Tools can fail, hang, or cause errors. Execute safely with timeouts, retries, and validation.

```python
import asyncio
import time
from functools import wraps
from typing import Callable, Any
import logging

logger = logging.getLogger(__name__)

# âœ… 1. Timeout decorator
def with_timeout(timeout_seconds: int):
    """Execute function with timeout"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            try:
                return await asyncio.wait_for(
                    func(*args, **kwargs),
                    timeout=timeout_seconds
                )
            except asyncio.TimeoutError:
                return f"Error: Tool execution timed out after {timeout_seconds}s"

        return async_wrapper
    return decorator

# âœ… 2. Retry decorator
def with_retries(max_retries: int = 3, backoff: float = 1.0):
    """Retry tool execution with exponential backoff"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(*args, **kwargs):
            last_error = None

            for attempt in range(max_retries):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_error = e

                    if attempt < max_retries - 1:
                        wait_time = backoff ** attempt
                        logger.warning(f"Attempt {attempt + 1} failed: {e}, retrying in {wait_time}s")
                        await asyncio.sleep(wait_time)

            return f"Error: Failed after {max_retries} attempts: {str(last_error)}"

        return wrapper
    return decorator

# âœ… 3. Safe tool wrapper
class SafeTool(BaseTool):
    """Wrapper for safe tool execution"""

    def __init__(self, base_tool: BaseTool, timeout: int = 10, max_retries: int = 2):
        self.base_tool = base_tool
        self.timeout = timeout
        self.max_retries = max_retries
        self.name = base_tool.name
        self.description = base_tool.description
        self.args_schema = base_tool.args_schema

    def _run(self, **kwargs) -> str:
        """Execute with safety measures"""
        try:
            # Validate inputs
            validated_kwargs = self._validate_inputs(**kwargs)

            # Execute with retries
            for attempt in range(self.max_retries):
                try:
                    # Execute with timeout
                    result = self._execute_with_timeout(validated_kwargs)
                    return str(result)
                except TimeoutError:
                    return f"Error: Tool timed out after {self.timeout}s"
                except Exception as e:
                    if attempt < self.max_retries - 1:
                        logger.warning(f"Tool attempt {attempt + 1} failed: {e}")
                        time.sleep(2 ** attempt)
                    else:
                        raise

        except Exception as e:
            return f"Error: {str(e)}"

    def _validate_inputs(self, **kwargs) -> dict:
        """Validate input parameters"""
        # Implement validation based on args_schema
        return kwargs

    def _execute_with_timeout(self, kwargs: dict):
        """Execute base tool with timeout"""
        # Simplified timeout implementation
        return self.base_tool._run(**kwargs)

    async def _arun(self, **kwargs) -> str:
        """Async safe execution"""
        return self._run(**kwargs)

# âœ… 4. Tool execution monitor
class ToolExecutionMonitor:
    def __init__(self):
        self.execution_history = []

    def monitor(self, tool_name: str, args: dict, result: Any, duration: float, success: bool):
        """Log tool execution"""
        self.execution_history.append({
            "tool": tool_name,
            "args": args,
            "result": result,
            "duration": duration,
            "success": success,
            "timestamp": time.time()
        })

    def get_stats(self, tool_name: str = None):
        """Get execution statistics"""
        history = self.execution_history

        if tool_name:
            history = [h for h in history if h["tool"] == tool_name]

        if not history:
            return None

        return {
            "total_calls": len(history),
            "successful": sum(1 for h in history if h["success"]),
            "failed": sum(1 for h in history if not h["success"]),
            "avg_duration": sum(h["duration"] for h in history) / len(history),
            "success_rate": sum(1 for h in history if h["success"]) / len(history)
        }

# Usage
monitor = ToolExecutionMonitor()

@tool
def safe_multiply(a: int, b: int) -> int:
    """Multiply two numbers"""
    start = time.time()
    try:
        result = a * b
        monitor.monitor("multiply", {"a": a, "b": b}, result, time.time() - start, True)
        return result
    except Exception as e:
        monitor.monitor("multiply", {"a": a, "b": b}, str(e), time.time() - start, False)
        return 0
```

---

### 4. **Build Custom Tool Sets**

**Why:** Group related tools together for organization and reusability.

```python
from typing import List
from langchain.tools import tool

class ToolKit:
    """Base class for organizing related tools"""

    def __init__(self, name: str, description: str):
        self.name = name
        self.description = description
        self.tools = []

    def add_tool(self, tool):
        """Add tool to toolkit"""
        self.tools.append(tool)

    def get_tools(self) -> List:
        """Get all tools"""
        return self.tools

    def get_tool_by_name(self, name: str):
        """Find tool by name"""
        for tool in self.tools:
            if tool.name == name:
                return tool
        return None

# âœ… Math toolkit
class MathToolkit(ToolKit):
    def __init__(self):
        super().__init__("Math", "Mathematical operations")

        @tool
        def add(a: int, b: int) -> int:
            """Add two numbers"""
            return a + b

        @tool
        def subtract(a: int, b: int) -> int:
            """Subtract two numbers"""
            return a - b

        @tool
        def multiply(a: int, b: int) -> int:
            """Multiply two numbers"""
            return a * b

        @tool
        def divide(a: float, b: float) -> float:
            """Divide two numbers"""
            if b == 0:
                return 0
            return a / b

        self.add_tool(add)
        self.add_tool(subtract)
        self.add_tool(multiply)
        self.add_tool(divide)

# âœ… Web toolkit
class WebToolkit(ToolKit):
    def __init__(self):
        super().__init__("Web", "Web and internet operations")

        @tool
        def search(query: str) -> str:
            """Search the web"""
            # Implementation
            return f"Search results for: {query}"

        @tool
        def fetch_url(url: str) -> str:
            """Fetch URL content"""
            # Implementation
            return f"Content from: {url}"

        self.add_tool(search)
        self.add_tool(fetch_url)

# âœ… File toolkit
class FileToolkit(ToolKit):
    def __init__(self):
        super().__init__("Files", "File and directory operations")

        @tool
        def read_file(path: str) -> str:
            """Read file content"""
            try:
                with open(path, 'r') as f:
                    return f.read()
            except Exception as e:
                return f"Error: {str(e)}"

        @tool
        def write_file(path: str, content: str) -> str:
            """Write content to file"""
            try:
                with open(path, 'w') as f:
                    f.write(content)
                return f"File written: {path}"
            except Exception as e:
                return f"Error: {str(e)}"

        self.add_tool(read_file)
        self.add_tool(write_file)

# âœ… Toolkit registry
class ToolkitRegistry:
    def __init__(self):
        self.toolkits = {}

    def register(self, toolkit: ToolKit):
        """Register a toolkit"""
        self.toolkits[toolkit.name] = toolkit

    def get_toolkit(self, name: str) -> ToolKit:
        """Get toolkit by name"""
        return self.toolkits.get(name)

    def get_all_tools(self) -> List:
        """Get all tools from all toolkits"""
        all_tools = []
        for toolkit in self.toolkits.values():
            all_tools.extend(toolkit.get_tools())
        return all_tools

    def list_toolkits(self) -> List[str]:
        """List available toolkits"""
        return list(self.toolkits.keys())

# Usage
registry = ToolkitRegistry()
registry.register(MathToolkit())
registry.register(WebToolkit())
registry.register(FileToolkit())

all_tools = registry.get_all_tools()
print(f"Available toolkits: {registry.list_toolkits()}")
```

---

### 5. **Implement Agent Memory and State Management**

**Why:** Agents need to remember previous interactions and maintain state across multiple steps.

```python
from langchain.memory import ConversationBufferMemory
from datetime import datetime
import json

class AgentState:
    """Manage agent state across steps"""

    def __init__(self):
        self.variables = {}
        self.history = []
        self.created_at = datetime.now()

    def set(self, key: str, value: Any):
        """Set state variable"""
        self.variables[key] = value

    def get(self, key: str, default=None):
        """Get state variable"""
        return self.variables.get(key, default)

    def add_history(self, action: str, result: Any):
        """Add to execution history"""
        self.history.append({
            "action": action,
            "result": result,
            "timestamp": datetime.now().isoformat()
        })

    def get_context(self) -> str:
        """Get current state as context for agent"""
        context = "Current state:\n"
        for key, value in self.variables.items():
            context += f"- {key}: {value}\n"
        return context

# âœ… Agent with memory
class MemorizedAgent:
    def __init__(self, agent_executor, memory_type: str = "buffer"):
        self.agent = agent_executor
        self.memory = ConversationBufferMemory(return_messages=True) if memory_type == "buffer" else None
        self.state = AgentState()

    def invoke(self, input_text: str) -> dict:
        """Execute agent with memory"""

        # Get memory context
        memory_context = ""
        if self.memory:
            memory_vars = self.memory.load_memory_variables({})
            if "history" in memory_vars:
                memory_context = str(memory_vars["history"])

        # Add input to memory
        if self.memory:
            self.memory.chat_memory.add_user_message(input_text)

        # Execute agent
        result = self.agent.invoke({
            "input": input_text,
            "memory": memory_context
        })

        # Add output to memory
        if self.memory:
            self.memory.chat_memory.add_ai_message(result["output"])

        # Update state
        self.state.add_history(input_text, result)

        return result

    def get_memory(self) -> str:
        """Get conversation history"""
        if self.memory:
            return str(self.memory.load_memory_variables({}))
        return ""

# âœ… Persistent agent state
class PersistentAgentState:
    def __init__(self, agent_id: str, storage_path: str = ".agent_state"):
        self.agent_id = agent_id
        self.storage_path = storage_path
        self.state = {}
        self.load()

    def save(self):
        """Persist state to disk"""
        import os
        os.makedirs(self.storage_path, exist_ok=True)

        filepath = os.path.join(self.storage_path, f"{self.agent_id}.json")
        with open(filepath, 'w') as f:
            json.dump(self.state, f, indent=2, default=str)

    def load(self):
        """Load state from disk"""
        import os
        filepath = os.path.join(self.storage_path, f"{self.agent_id}.json")

        if os.path.exists(filepath):
            with open(filepath, 'r') as f:
                self.state = json.load(f)

    def update(self, key: str, value: Any):
        """Update state and save"""
        self.state[key] = value
        self.save()

# Usage
state = PersistentAgentState("agent_001")
state.update("user_name", "Alice")
state.update("conversation_count", 5)
```

---

### 6. **Implement Agent Logging and Debugging**

**Why:** Agents are complex. You need visibility into their decision-making and execution.

```python
import logging
from datetime import datetime
from typing import Any, Dict

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AgentLogger:
    """Comprehensive agent execution logging"""

    def __init__(self, agent_name: str):
        self.agent_name = agent_name
        self.logs = []

    def log_step(self, step_num: int, action: str, input_data: Any, output: Any):
        """Log a single agent step"""
        log_entry = {
            "step": step_num,
            "timestamp": datetime.now().isoformat(),
            "action": action,
            "input": str(input_data)[:500],  # Limit length
            "output": str(output)[:500]
        }

        self.logs.append(log_entry)

        logger.info(
            f"[{self.agent_name}] Step {step_num}: {action}\n"
            f"  Input: {input_data}\n"
            f"  Output: {output}"
        )

    def log_error(self, step_num: int, error: Exception):
        """Log errors"""
        log_entry = {
            "step": step_num,
            "timestamp": datetime.now().isoformat(),
            "error": str(error),
            "type": error.__class__.__name__
        }

        self.logs.append(log_entry)
        logger.error(f"[{self.agent_name}] Error at step {step_num}: {error}")

    def get_trace(self) -> str:
        """Get formatted execution trace"""
        trace = f"Agent: {self.agent_name}\n"
        trace += "=" * 50 + "\n"

        for log in self.logs:
            trace += f"Step {log['step']}: {log['timestamp']}\n"
            if "action" in log:
                trace += f"  Action: {log['action']}\n"
                trace += f"  Input: {log['input']}\n"
                trace += f"  Output: {log['output']}\n"
            else:
                trace += f"  ERROR: {log['error']}\n"

        return trace

    def get_stats(self) -> Dict[str, Any]:
        """Get execution statistics"""
        total_steps = len([l for l in self.logs if "action" in l])
        errors = len([l for l in self.logs if "error" in l])

        return {
            "total_steps": total_steps,
            "errors": errors,
            "success_rate": (total_steps - errors) / total_steps if total_steps > 0 else 0,
            "duration": (
                datetime.fromisoformat(self.logs[-1]["timestamp"]) -
                datetime.fromisoformat(self.logs[0]["timestamp"])
            ).total_seconds() if self.logs else 0
        }

# âœ… Debug callback for agents
from langchain_core.callbacks import BaseCallbackHandler

class AgentDebugCallback(BaseCallbackHandler):
    """Callback for detailed agent debugging"""

    def on_agent_action(self, action, **kwargs):
        """Called when agent takes action"""
        logger.info(f"Agent Action: {action.tool}")
        logger.info(f"Tool Input: {action.tool_input}")

    def on_agent_finish(self, finish, **kwargs):
        """Called when agent finishes"""
        logger.info(f"Agent Finish: {finish.output}")

    def on_tool_start(self, serialized, input_str, **kwargs):
        """Called when tool starts"""
        logger.info(f"Tool Start: {serialized['name']}")

    def on_tool_end(self, output, **kwargs):
        """Called when tool ends"""
        logger.info(f"Tool Output: {output}")

    def on_tool_error(self, error, **kwargs):
        """Called on tool error"""
        logger.error(f"Tool Error: {error}")

# Usage
logger = AgentLogger("my_agent")
debug_callback = AgentDebugCallback()

# Execute agent with logging
result = agent_executor.invoke(
    {"input": "Calculate 10 * 5"},
    {"callbacks": [debug_callback]}
)

# Get execution trace
print(logger.get_trace())
print(logger.get_stats())
```

---

### 7. **Implement Agent Error Handling and Recovery**

**Why:** Agents fail. Handle errors gracefully with recovery strategies.

```python
from typing import Optional
import time

class AgentErrorHandler:
    """Handle and recover from agent errors"""

    def __init__(self, max_retries: int = 3):
        self.max_retries = max_retries
        self.error_history = []

    def execute_with_recovery(self, agent_func, input_data, retries: int = 0):
        """Execute agent with error recovery"""

        try:
            return agent_func(input_data)

        except ValueError as e:
            # Input validation error
            logger.warning(f"Input error: {e}")

            if retries < self.max_retries:
                # Try again with corrected input
                logger.info("Retrying with default input")
                return agent_func(self._get_default_input(input_data))
            else:
                return {
                    "error": "Invalid input",
                    "message": str(e)
                }

        except TimeoutError as e:
            # Timeout error
            logger.warning(f"Timeout: {e}")

            if retries < self.max_retries:
                wait_time = 2 ** retries
                logger.info(f"Waiting {wait_time}s before retry")
                time.sleep(wait_time)
                return self.execute_with_recovery(agent_func, input_data, retries + 1)
            else:
                return {
                    "error": "Timeout",
                    "message": "Agent execution timed out"
                }

        except Exception as e:
            # Generic error
            logger.error(f"Unexpected error: {e}")

            # Record error
            self.error_history.append({
                "error": str(e),
                "type": e.__class__.__name__,
                "timestamp": datetime.now().isoformat()
            })

            if retries < self.max_retries:
                logger.info(f"Retry {retries + 1}/{self.max_retries}")
                time.sleep(1)
                return self.execute_with_recovery(agent_func, input_data, retries + 1)
            else:
                return {
                    "error": "Execution failed",
                    "message": str(e),
                    "attempts": retries + 1
                }

    def _get_default_input(self, input_data):
        """Get default/corrected input"""
        if isinstance(input_data, dict):
            return {"input": "Help me"}
        return "Help me"

    def get_error_summary(self) -> Dict[str, Any]:
        """Get summary of errors"""
        if not self.error_history:
            return {"total_errors": 0}

        error_types = {}
        for error in self.error_history:
            error_type = error["type"]
            error_types[error_type] = error_types.get(error_type, 0) + 1

        return {
            "total_errors": len(self.error_history),
            "error_types": error_types,
            "most_common": max(error_types, key=error_types.get) if error_types else None
        }

# âœ… Fallback agent
class FallbackAgent:
    """Use fallback agent if primary fails"""

    def __init__(self, primary_agent, fallback_agent):
        self.primary = primary_agent
        self.fallback = fallback_agent

    def invoke(self, input_data: dict):
        """Try primary, fall back if needed"""

        try:
            return self.primary.invoke(input_data)
        except Exception as e:
            logger.warning(f"Primary agent failed: {e}, using fallback")
            try:
                return self.fallback.invoke(input_data)
            except Exception as fallback_error:
                logger.error(f"Fallback also failed: {fallback_error}")
                return {
                    "error": "Both primary and fallback agents failed",
                    "primary_error": str(e),
                    "fallback_error": str(fallback_error)
                }

# Usage
error_handler = AgentErrorHandler(max_retries=3)

result = error_handler.execute_with_recovery(
    agent.invoke,
    {"input": "What is 2+2?"}
)
```

---

### 8. **Implement Agent Planning and Reasoning**

**Why:** Better planning = better execution. Help agents think before acting.

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

class PlanningAgent:
    """Agent that plans before execution"""

    def __init__(self, llm):
        self.llm = llm

    def create_plan(self, objective: str) -> str:
        """Create execution plan"""

        prompt = ChatPromptTemplate.from_template(
            """Create a detailed plan to achieve this objective.

Objective: {objective}

Plan (step by step):"""
        )

        response = (prompt | self.llm).invoke({"objective": objective})
        return response.content

    def evaluate_plan(self, plan: str, constraint: str = None) -> dict:
        """Evaluate plan quality"""

        prompt = ChatPromptTemplate.from_template(
            """Evaluate this plan:

{plan}

Is this plan:
1. Clear and specific?
2. Feasible?
3. Efficient?

Provide scores 0-10 for each."""
        )

        response = (prompt | self.llm).invoke({"plan": plan})

        # Parse evaluation
        return {
            "evaluation": response.content,
            "summary": "Plan looks good" if "good" in response.content.lower() else "Plan needs improvement"
        }

    def refine_plan(self, plan: str, feedback: str) -> str:
        """Refine plan based on feedback"""

        prompt = ChatPromptTemplate.from_template(
            """Refine this plan based on feedback:

Original Plan:
{plan}

Feedback:
{feedback}

Refined Plan:"""
        )

        response = (prompt | self.llm).invoke({
            "plan": plan,
            "feedback": feedback
        })

        return response.content

# âœ… Reasoning chain
class ReasoningChain:
    """Agent with explicit reasoning steps"""

    def __init__(self, llm):
        self.llm = llm

    def invoke(self, query: str) -> dict:
        """Execute with explicit reasoning"""

        # Step 1: Understand
        understand_prompt = ChatPromptTemplate.from_template(
            "Understand this query: {query}\n\nUnderstanding:"
        )
        understanding = (understand_prompt | self.llm).invoke({"query": query})

        # Step 2: Reason
        reason_prompt = ChatPromptTemplate.from_template(
            """Given this understanding: {understanding}

What reasoning applies?"""
        )
        reasoning = (reason_prompt | self.llm).invoke({
            "understanding": understanding.content
        })

        # Step 3: Conclude
        conclude_prompt = ChatPromptTemplate.from_template(
            """Based on this reasoning: {reasoning}

What is the conclusion?"""
        )
        conclusion = (conclude_prompt | self.llm).invoke({
            "reasoning": reasoning.content
        })

        return {
            "query": query,
            "understanding": understanding.content,
            "reasoning": reasoning.content,
            "conclusion": conclusion.content
        }

# Usage
planner = PlanningAgent(ChatOpenAI(model="gpt-4"))

plan = planner.create_plan("Build a RAG system for customer documents")
evaluation = planner.evaluate_plan(plan)
refined = planner.refine_plan(plan, evaluation["summary"])
```

---

### 9. **Implement Agent Streaming and Real-Time Feedback**

**Why:** Users want real-time feedback, not waits for final answer.

```python
from typing import Iterator
import asyncio

class StreamingAgent:
    """Agent that streams results"""

    def __init__(self, agent_executor):
        self.agent = agent_executor

    def invoke_streaming(self, input_data: dict) -> Iterator[str]:
        """Stream agent output in real-time"""

        # Execute agent
        for step in self.agent.iter(input_data):
            if "actions" in step:
                for action in step["actions"]:
                    yield f"ğŸ”§ Tool: {action.tool}\n"
                    yield f"   Input: {action.tool_input}\n"

            if "observation" in step:
                yield f"ğŸ“Š Result: {step['observation']}\n"

            if "final_answer" in step:
                yield f"âœ… Answer: {step['final_answer']}\n"

    async def ainvoke_streaming(self, input_data: dict):
        """Async streaming"""

        async for item in self.agent.astream(input_data):
            yield item

# âœ… Progress callback
class ProgressCallback(BaseCallbackHandler):
    """Report progress during execution"""

    def __init__(self, progress_fn):
        self.progress_fn = progress_fn
        self.step_count = 0

    def on_agent_action(self, action, **kwargs):
        """Report tool action"""
        self.step_count += 1
        self.progress_fn(f"Step {self.step_count}: Using {action.tool}")

    def on_tool_end(self, output, **kwargs):
        """Report tool completion"""
        self.progress_fn(f"  â†’ Result received")

# Usage
streaming_agent = StreamingAgent(agent_executor)

# Stream results
for update in streaming_agent.invoke_streaming({"input": "Calculate 10 * 5"}):
    print(update, end="", flush=True)

# With progress
progress = lambda msg: print(f"ğŸ“ {msg}")
callback = ProgressCallback(progress)

result = agent_executor.invoke(
    {"input": "What is the capital of France?"},
    {"callbacks": [callback]}
)
```

---

### 10. **Implement Multi-Agent Systems**

**Why:** Complex tasks benefit from agents with different specialties collaborating.

```python
from typing import List

class MultiAgentSystem:
    """Coordinate multiple agents"""

    def __init__(self):
        self.agents = {}
        self.coordinator_llm = ChatOpenAI(model="gpt-4")

    def register_agent(self, name: str, agent, specialty: str):
        """Register an agent"""
        self.agents[name] = {
            "agent": agent,
            "specialty": specialty
        }

    def select_agent(self, query: str) -> str:
        """Select best agent for task"""

        prompt = ChatPromptTemplate.from_template(
            """Given these available agents:
{agents_list}

Which agent is best for this query?
Query: {query}

Agent name:"""
        )

        agents_list = "\n".join([
            f"- {name}: {info['specialty']}"
            for name, info in self.agents.items()
        ])

        response = (prompt | self.coordinator_llm).invoke({
            "agents_list": agents_list,
            "query": query
        })

        # Parse response to get agent name
        agent_name = response.content.strip().lower()
        return agent_name if agent_name in self.agents else list(self.agents.keys())[0]

    def invoke(self, query: str) -> dict:
        """Execute with agent selection"""

        # Select best agent
        agent_name = self.select_agent(query)
        agent = self.agents[agent_name]["agent"]

        # Execute
        result = agent.invoke({"input": query})

        return {
            "query": query,
            "agent": agent_name,
            "result": result["output"]
        }

    def collaborative_invoke(self, query: str) -> dict:
        """Use multiple agents collaboratively"""

        responses = {}

        # Get input from each agent
        for agent_name, agent_info in self.agents.items():
            try:
                response = agent_info["agent"].invoke({"input": query})
                responses[agent_name] = response["output"]
            except:
                responses[agent_name] = "Unable to process"

        # Synthesize responses
        synthesis_prompt = ChatPromptTemplate.from_template(
            """Given these expert perspectives:
{perspectives}

Query: {query}

Synthesized answer:"""
        )

        perspectives = "\n".join([
            f"{name}: {response}"
            for name, response in responses.items()
        ])

        synthesis = (synthesis_prompt | self.coordinator_llm).invoke({
            "perspectives": perspectives,
            "query": query
        })

        return {
            "query": query,
            "individual_responses": responses,
            "synthesis": synthesis.content
        }

# Usage
multi_agent = MultiAgentSystem()

# Register agents
multi_agent.register_agent("calculator", math_agent, "Mathematical calculations")
multi_agent.register_agent("researcher", research_agent, "Web research and facts")
multi_agent.register_agent("analyst", analysis_agent, "Data analysis")

# Single agent selection
result = multi_agent.invoke("What is 50 * 50?")

# Collaborative
result = multi_agent.collaborative_invoke("Explain machine learning")
```

---

## ğŸ¯ Part 2: Tips & Tricks for Agents

### Trick 1: **Implement Agent Self-Critique**

Agent evaluates its own output and corrects if needed.

```python
class SelfCritiquingAgent:
    def __init__(self, agent_executor, llm):
        self.agent = agent_executor
        self.llm = llm

    def invoke_with_critique(self, query: str, max_iterations: int = 2):
        """Execute agent with self-critique"""

        for iteration in range(max_iterations):
            # Execute
            result = self.agent.invoke({"input": query})
            output = result["output"]

            # Critique
            critique_prompt = ChatPromptTemplate.from_template(
                """Evaluate this response to: {query}

Response: {response}

Is this response:
1. Accurate?
2. Complete?
3. Helpful?

Rate each 1-10. If score < 7, suggest improvement."""
            )

            critique = (critique_prompt | self.llm).invoke({
                "query": query,
                "response": output
            })

            if "improve" not in critique.content.lower():
                return output

            # Refine if needed
            query = f"{query}\n\nFeedback: {critique.content}"

        return output
```

---

### Trick 2: **Implement Agent Thought Tracking**

Track agent's "thoughts" separate from actions.

```python
class ThoughtfulAgent:
    def __init__(self, agent_executor):
        self.agent = agent_executor
        self.thoughts = []

    def invoke(self, query: str):
        """Execute and track thoughts"""

        # Instruction to include thinking
        thinking_prompt = f"""{query}

Please think through this step by step:
1. What do I need to find out?
2. What tools should I use?
3. What's my approach?

Then execute."""

        result = self.agent.invoke({"input": thinking_prompt})

        # Extract and store thoughts
        self.thoughts.append({
            "query": query,
            "response": result["output"],
            "timestamp": datetime.now().isoformat()
        })

        return result

    def get_thought_history(self) -> List[dict]:
        """Get all thoughts"""
        return self.thoughts
```

---

### Trick 3: **Implement Agent Tool Caching**

Cache tool results to avoid redundant calls.

```python
class CachedToolAgent:
    def __init__(self, agent_executor):
        self.agent = agent_executor
        self.tool_cache = {}

    def _get_cache_key(self, tool_name: str, args: dict) -> str:
        """Create cache key"""
        return f"{tool_name}:{str(sorted(args.items()))}"

    def invoke(self, query: str):
        """Execute with tool caching"""

        # Wrap tools with caching
        cached_agent = self._wrap_agent_with_cache()
        return cached_agent.invoke({"input": query})

    def _wrap_agent_with_cache(self):
        """Wrap agent tools with cache"""
        # Implementation would wrap the agent's tools
        return self.agent

    def clear_cache(self):
        """Clear tool cache"""
        self.tool_cache.clear()
```

---

### Trick 4: **Implement Dynamic Tool Selection**

Only provide relevant tools for the task.

```python
class DynamicToolAgent:
    def __init__(self, all_tools: List, llm):
        self.all_tools = all_tools
        self.llm = llm

    def select_tools(self, query: str, k: int = 5):
        """Select most relevant tools"""

        prompt = ChatPromptTemplate.from_template(
            """Given these tools:
{tools_list}

Which {k} are most useful for: {query}

Tool names (comma separated):"""
        )

        tools_desc = "\n".join([f"- {t.name}: {t.description}" for t in self.all_tools])

        response = (prompt | self.llm).invoke({
            "tools_list": tools_desc,
            "query": query,
            "k": k
        })

        # Parse and select
        selected_names = [n.strip() for n in response.content.split(",")]
        return [t for t in self.all_tools if t.name in selected_names]
```

---

### Trick 5: **Implement Agent Explanation Generation**

Generate explanations for agent decisions.

```python
class ExplainableAgent:
    def __init__(self, agent_executor, llm):
        self.agent = agent_executor
        self.llm = llm

    def invoke_with_explanation(self, query: str):
        """Execute and explain reasoning"""

        result = self.agent.invoke({"input": query})

        # Generate explanation
        explain_prompt = ChatPromptTemplate.from_template(
            """Explain how you arrived at this answer:

Query: {query}
Answer: {answer}

Explanation (step by step):"""
        )

        explanation = (explain_prompt | self.llm).invoke({
            "query": query,
            "answer": result["output"]
        })

        return {
            "answer": result["output"],
            "explanation": explanation.content
        }
```

---

### Trick 6: **Implement Agent Confidence Scoring**

Agent reports confidence in its answer.

```python
class ConfidentAgent:
    def __init__(self, agent_executor, llm):
        self.agent = agent_executor
        self.llm = llm

    def invoke_with_confidence(self, query: str):
        """Execute and score confidence"""

        result = self.agent.invoke({"input": query})
        output = result["output"]

        # Score confidence
        confidence_prompt = ChatPromptTemplate.from_template(
            """How confident are you in this answer? (0-100)

Query: {query}
Answer: {answer}

Confidence score:"""
        )

        confidence_response = (confidence_prompt | self.llm).invoke({
            "query": query,
            "answer": output
        })

        try:
            score = int(confidence_response.content.split()[-1])
        except:
            score = 50

        return {
            "answer": output,
            "confidence": score,
            "high_confidence": score > 70
        }
```

---

### Trick 7: **Implement Agent Parallelization**

Execute multiple agents in parallel.

```python
import asyncio
from typing import List

class ParallelAgent:
    def __init__(self, agents: List):
        self.agents = agents

    async def invoke_all_async(self, query: str):
        """Execute all agents in parallel"""

        tasks = [
            agent.ainvoke({"input": query})
            for agent in self.agents
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)
        return results

    def invoke_all(self, query: str):
        """Sync version using asyncio.run"""
        return asyncio.run(self.invoke_all_async(query))
```

---

### Trick 8: **Implement Agent A/B Testing**

Compare different agent configurations.

```python
class AgentABTest:
    def __init__(self):
        self.results = {
            "agent_a": [],
            "agent_b": []
        }

    def run_test(self, agent_a, agent_b, test_queries: List[str]):
        """Compare two agents"""

        for query in test_queries:
            # Test agent A
            try:
                result_a = agent_a.invoke({"input": query})
                self.results["agent_a"].append({
                    "query": query,
                    "success": True,
                    "output": result_a.get("output", ""),
                    "time": 0  # Would measure time
                })
            except Exception as e:
                self.results["agent_a"].append({
                    "query": query,
                    "success": False,
                    "error": str(e)
                })

            # Test agent B
            try:
                result_b = agent_b.invoke({"input": query})
                self.results["agent_b"].append({
                    "query": query,
                    "success": True,
                    "output": result_b.get("output", ""),
                    "time": 0
                })
            except Exception as e:
                self.results["agent_b"].append({
                    "query": query,
                    "success": False,
                    "error": str(e)
                })

    def compare(self) -> dict:
        """Compare results"""

        success_a = sum(1 for r in self.results["agent_a"] if r.get("success"))
        success_b = sum(1 for r in self.results["agent_b"] if r.get("success"))

        return {
            "agent_a_success_rate": success_a / len(self.results["agent_a"]),
            "agent_b_success_rate": success_b / len(self.results["agent_b"]),
            "winner": "agent_a" if success_a > success_b else "agent_b"
        }
```

---

### Trick 9: **Implement Agent Personas**

Create agents with different personalities/styles.

```python
class PersonaAgent:
    PERSONAS = {
        "technical": "Provide detailed technical explanations with code examples",
        "casual": "Explain informally as if talking to a friend",
        "formal": "Use formal business language and structure",
        "creative": "Be creative and use analogies and stories",
    }

    def __init__(self, agent_executor, persona: str = "technical"):
        self.agent = agent_executor
        self.persona = persona

    def invoke(self, query: str):
        """Execute with persona"""

        persona_instruction = self.PERSONAS.get(self.persona, "")

        enhanced_query = f"""{query}

Style: {persona_instruction}"""

        return self.agent.invoke({"input": enhanced_query})
```

---

### Trick 10: **Implement Agent Chain of Thought Prompting**

Force explicit step-by-step reasoning.

```python
class ChainOfThoughtAgent:
    def __init__(self, agent_executor, llm):
        self.agent = agent_executor
        self.llm = llm

    def invoke_with_cot(self, query: str):
        """Execute with chain-of-thought"""

        cot_prompt = f"""{query}

Let me think through this step by step:
1. First, I need to...
2. Then, I should...
3. Finally, I will...

Let me proceed:"""

        result = self.agent.invoke({"input": cot_prompt})
        return result
```

---

## ğŸ“Š Quick Reference: Agent Types Comparison

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent Type       â”‚ Reasoning   â”‚ Speed     â”‚ Transparencyâ”‚ Best For     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ReAct            â”‚ Excellent   â”‚ Medium    â”‚ High        â”‚ Complex      â”‚
â”‚ Tool Calling     â”‚ Good        â”‚ Fast      â”‚ Medium      â”‚ Fast exec    â”‚
â”‚ OpenAI Asst      â”‚ Excellent   â”‚ Medium    â”‚ High        â”‚ Workflows    â”‚
â”‚ Custom           â”‚ Variable    â”‚ Variable  â”‚ Variable    â”‚ Specialized  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– Agent Development Checklist

- [ ] Tool definitions are complete and correct
- [ ] Tools have proper input/output schemas
- [ ] Error handling implemented for all tools
- [ ] Timeout protection for long-running tools
- [ ] Tool caching to reduce API calls
- [ ] Agent type chosen for use case
- [ ] Logging and debugging enabled
- [ ] Memory management implemented
- [ ] Error recovery strategies in place
- [ ] Agent reasoning documented
- [ ] Multi-agent coordination if needed
- [ ] Performance monitoring enabled
- [ ] Fallback agents configured

---

## ğŸš€ Production Agent Checklist

- [ ] All tools tested individually
- [ ] Agent tested with various inputs
- [ ] Error handling comprehensive
- [ ] Logging captures all important events
- [ ] Rate limiting implemented
- [ ] Cost tracking enabled
- [ ] Fallback/recovery strategies active
- [ ] Performance metrics monitored
- [ ] Multi-user isolation ensured
- [ ] Tool execution timeout enforced
- [ ] Memory limits respected
- [ ] Load testing completed
- [ ] Rollback plan documented

---

**Build intelligent agents. Create autonomous systems. Solve complex problems.** ğŸ¤–âœ¨
